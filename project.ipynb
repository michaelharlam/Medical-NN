{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelharlam/Medical-NN/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Edat58REm9D_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KoB2Y8vH7hG9",
        "outputId": "43e31361-c557-45da-8cba-578a260d1694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device # должен быть cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QurMgEGVmhLo"
      },
      "source": [
        "# Хронология создания нашего проекта"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX8r30gwmhLq"
      },
      "source": [
        "Изначально мы решили сделать простейшую классификацию с помощью глубокой ResNet-модели, которая к сожалению, не сохранилась. Мы получили достаточно неплохой результат со значением F1-Score 0.84\n",
        "\n",
        "После этого мы принялись за разработку более сложной структуры, включающей в себя 2 модели - сегментирующую и классификационную.\n",
        "прочитав несколько статей о медецинской сфере, в качестве сегментирующей модели мы решили выбрать U-Net, а классификационную так и оставили ResNet'ом.\n",
        "\n",
        "Изначально архитектура U-Net'а была сложнее и глубже, но после многочисленных тестов, мы пришли к выводу, что упрошенная архитектура с меньшей глубиной и обучаться будет в разы быстрее, и не сожмет исходное изображение слишком сильно. Нижепердставленная сегментирующая модель - наилучшая, из тех, что мы смогли придумать, по соотношению \"время обучения / качество\". На \"бумаге\" она показывает неплохие результаты MSE (в среденем ~0.018), а на практике достаточно точно выделяет легкие на изображениях.\n",
        "\n",
        "ResNet стал для нас самой трудной задачей, поскольку в нашем случае он получался очень нестабильным (незначительное изменение learning rate быо способно испортить результат на ~30%). Опробовав достаточно большое кол-во архитектур, мы так и не смогли найти достаточно хорошую. И самый лучший F1-Score, получившийся в резульате работы системы из двух моделей на тестовой выборке - 0.73\n",
        "\n",
        "Мы думаем, что главная проблема нашей команды - распределение задач. Размышляя о проделанной работе, мы понимаем, что могли опробовать больше вариантов классификационных моделей и / или создать более сложную систему классификации, что значительно улучшило бы итоговый результат."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EslgprW6aThM"
      },
      "source": [
        "# Сегментирующая модель U-Net (1 этап)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPtUJTMyag2L",
        "outputId": "4fe3f77e-0b71-4211-ca2c-4b5b72ce1f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 254, 254]             160\n",
            "       BatchNorm2d-2         [-1, 16, 254, 254]              32\n",
            "              ReLU-3         [-1, 16, 254, 254]               0\n",
            "            Conv2d-4         [-1, 16, 252, 252]           2,320\n",
            "       BatchNorm2d-5         [-1, 16, 252, 252]              32\n",
            "              ReLU-6         [-1, 16, 252, 252]               0\n",
            "     UNetConvBlock-7         [-1, 16, 252, 252]               0\n",
            "         MaxPool2d-8         [-1, 16, 126, 126]               0\n",
            "            Conv2d-9         [-1, 32, 124, 124]           4,640\n",
            "      BatchNorm2d-10         [-1, 32, 124, 124]              64\n",
            "             ReLU-11         [-1, 32, 124, 124]               0\n",
            "           Conv2d-12         [-1, 32, 122, 122]           9,248\n",
            "      BatchNorm2d-13         [-1, 32, 122, 122]              64\n",
            "             ReLU-14         [-1, 32, 122, 122]               0\n",
            "    UNetConvBlock-15         [-1, 32, 122, 122]               0\n",
            "        MaxPool2d-16           [-1, 32, 61, 61]               0\n",
            "           Conv2d-17           [-1, 64, 59, 59]          18,496\n",
            "      BatchNorm2d-18           [-1, 64, 59, 59]             128\n",
            "             ReLU-19           [-1, 64, 59, 59]               0\n",
            "           Conv2d-20           [-1, 64, 57, 57]          36,928\n",
            "      BatchNorm2d-21           [-1, 64, 57, 57]             128\n",
            "             ReLU-22           [-1, 64, 57, 57]               0\n",
            "    UNetConvBlock-23           [-1, 64, 57, 57]               0\n",
            "         Upsample-24         [-1, 64, 114, 114]               0\n",
            "  ConvTranspose2d-25         [-1, 32, 114, 114]           2,080\n",
            "             ReLU-26         [-1, 32, 114, 114]               0\n",
            "           UpConv-27         [-1, 32, 114, 114]               0\n",
            "           Conv2d-28         [-1, 32, 112, 112]          18,464\n",
            "      BatchNorm2d-29         [-1, 32, 112, 112]              64\n",
            "             ReLU-30         [-1, 32, 112, 112]               0\n",
            "           Conv2d-31         [-1, 32, 110, 110]           9,248\n",
            "      BatchNorm2d-32         [-1, 32, 110, 110]              64\n",
            "             ReLU-33         [-1, 32, 110, 110]               0\n",
            "    UNetConvBlock-34         [-1, 32, 110, 110]               0\n",
            "         Upsample-35         [-1, 32, 220, 220]               0\n",
            "  ConvTranspose2d-36         [-1, 16, 220, 220]             528\n",
            "             ReLU-37         [-1, 16, 220, 220]               0\n",
            "           UpConv-38         [-1, 16, 220, 220]               0\n",
            "           Conv2d-39         [-1, 16, 218, 218]           4,624\n",
            "      BatchNorm2d-40         [-1, 16, 218, 218]              32\n",
            "             ReLU-41         [-1, 16, 218, 218]               0\n",
            "           Conv2d-42         [-1, 16, 216, 216]           2,320\n",
            "      BatchNorm2d-43         [-1, 16, 216, 216]              32\n",
            "             ReLU-44         [-1, 16, 216, 216]               0\n",
            "    UNetConvBlock-45         [-1, 16, 216, 216]               0\n",
            "  ConvTranspose2d-46          [-1, 1, 216, 216]              17\n",
            "          Sigmoid-47          [-1, 1, 216, 216]               0\n",
            "================================================================\n",
            "Total params: 109,713\n",
            "Trainable params: 109,713\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.25\n",
            "Forward/backward pass size (MB): 202.03\n",
            "Params size (MB): 0.42\n",
            "Estimated Total Size (MB): 202.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms.v2.functional import center_crop\n",
        "\n",
        "class UNetConvBlock(nn.Module): # сверточный блок с задаваемым кол-вом входных/выходных каналов\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNetConvBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(out_channels, out_channels, 3),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UpConv(nn.Module): # реализация стрелки up-conv 2x2 с первой схемы\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpConv, self).__init__()\n",
        "        self.upconv = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.upconv(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "def stack(x_1: torch.Tensor, x_2: torch.Tensor): # функция принимающая 2 тензора и возвращающая более объемный тензор из них, идущих в нем по порядку (термина не знаю)\n",
        "    x_1 = center_crop(x_1, x_2.shape[-2:])\n",
        "    return torch.cat((x_1, x_2), -3)\n",
        "\n",
        "\n",
        "class UNetModel(nn.Module): # Сама модель (цифры в названии переменных - \"глубина\" слоя)\n",
        "    def __init__(self):\n",
        "        super(UNetModel, self).__init__()\n",
        "\n",
        "        self.conv1 = UNetConvBlock(1, 16)\n",
        "        # по порядку тут maxpool\n",
        "        self.conv2 = UNetConvBlock(16, 32)\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bridge = UNetConvBlock(32, 64)\n",
        "\n",
        "        self.upconv2 = UpConv(64, 32)\n",
        "        self.convt2 = UNetConvBlock(64, 32)\n",
        "        self.upconv1 = UpConv(32, 16)\n",
        "        self.convt1 = UNetConvBlock(32, 16)\n",
        "\n",
        "        self.post_processing = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.conv1(x)\n",
        "        out = self.maxpool(d1)\n",
        "\n",
        "        d2 = self.conv2(out)\n",
        "        out = self.maxpool(d2)\n",
        "\n",
        "        out = self.bridge(out)\n",
        "\n",
        "        out = self.upconv2(out)\n",
        "        out = self.convt2(stack(d2, out))\n",
        "\n",
        "        out = self.upconv1(out)\n",
        "        out = self.convt1(stack(d1, out))\n",
        "\n",
        "        out = self.post_processing(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "unet = UNetModel().to(device)\n",
        "summary(unet, (1, 256, 256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DPDw8CXaJKP"
      },
      "source": [
        "# Классификационная модель ResNet 18 (2 этап)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXBXBKVDnY11",
        "outputId": "a1965fcc-a8de-493b-d62c-3bb5aa81a4e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 112, 112]             400\n",
            "       BatchNorm2d-2          [-1, 8, 112, 112]              16\n",
            "              ReLU-3          [-1, 8, 112, 112]               0\n",
            "         MaxPool2d-4            [-1, 8, 56, 56]               0\n",
            "            Conv2d-5            [-1, 8, 56, 56]             584\n",
            "       BatchNorm2d-6            [-1, 8, 56, 56]              16\n",
            "              ReLU-7            [-1, 8, 56, 56]               0\n",
            "            Conv2d-8            [-1, 8, 56, 56]             584\n",
            "       BatchNorm2d-9            [-1, 8, 56, 56]              16\n",
            "             ReLU-10            [-1, 8, 56, 56]               0\n",
            "         ResBlock-11            [-1, 8, 56, 56]               0\n",
            "           Conv2d-12            [-1, 8, 56, 56]             584\n",
            "      BatchNorm2d-13            [-1, 8, 56, 56]              16\n",
            "             ReLU-14            [-1, 8, 56, 56]               0\n",
            "           Conv2d-15            [-1, 8, 56, 56]             584\n",
            "      BatchNorm2d-16            [-1, 8, 56, 56]              16\n",
            "             ReLU-17            [-1, 8, 56, 56]               0\n",
            "         ResBlock-18            [-1, 8, 56, 56]               0\n",
            "           Conv2d-19           [-1, 16, 28, 28]           1,168\n",
            "      BatchNorm2d-20           [-1, 16, 28, 28]              32\n",
            "             ReLU-21           [-1, 16, 28, 28]               0\n",
            "           Conv2d-22           [-1, 16, 28, 28]           2,320\n",
            "      BatchNorm2d-23           [-1, 16, 28, 28]              32\n",
            "             ReLU-24           [-1, 16, 28, 28]               0\n",
            "  ResNetConvBlock-25           [-1, 16, 28, 28]               0\n",
            "           Conv2d-26           [-1, 16, 28, 28]           2,320\n",
            "      BatchNorm2d-27           [-1, 16, 28, 28]              32\n",
            "             ReLU-28           [-1, 16, 28, 28]               0\n",
            "           Conv2d-29           [-1, 16, 28, 28]           2,320\n",
            "      BatchNorm2d-30           [-1, 16, 28, 28]              32\n",
            "             ReLU-31           [-1, 16, 28, 28]               0\n",
            "         ResBlock-32           [-1, 16, 28, 28]               0\n",
            "           Conv2d-33           [-1, 16, 28, 28]           2,320\n",
            "      BatchNorm2d-34           [-1, 16, 28, 28]              32\n",
            "             ReLU-35           [-1, 16, 28, 28]               0\n",
            "           Conv2d-36           [-1, 16, 28, 28]           2,320\n",
            "      BatchNorm2d-37           [-1, 16, 28, 28]              32\n",
            "             ReLU-38           [-1, 16, 28, 28]               0\n",
            "         ResBlock-39           [-1, 16, 28, 28]               0\n",
            "           Conv2d-40           [-1, 32, 14, 14]           4,640\n",
            "      BatchNorm2d-41           [-1, 32, 14, 14]              64\n",
            "             ReLU-42           [-1, 32, 14, 14]               0\n",
            "           Conv2d-43           [-1, 32, 14, 14]           9,248\n",
            "      BatchNorm2d-44           [-1, 32, 14, 14]              64\n",
            "             ReLU-45           [-1, 32, 14, 14]               0\n",
            "  ResNetConvBlock-46           [-1, 32, 14, 14]               0\n",
            "           Conv2d-47           [-1, 32, 14, 14]           9,248\n",
            "      BatchNorm2d-48           [-1, 32, 14, 14]              64\n",
            "             ReLU-49           [-1, 32, 14, 14]               0\n",
            "           Conv2d-50           [-1, 32, 14, 14]           9,248\n",
            "      BatchNorm2d-51           [-1, 32, 14, 14]              64\n",
            "             ReLU-52           [-1, 32, 14, 14]               0\n",
            "         ResBlock-53           [-1, 32, 14, 14]               0\n",
            "           Conv2d-54           [-1, 32, 14, 14]           9,248\n",
            "      BatchNorm2d-55           [-1, 32, 14, 14]              64\n",
            "             ReLU-56           [-1, 32, 14, 14]               0\n",
            "           Conv2d-57           [-1, 32, 14, 14]           9,248\n",
            "      BatchNorm2d-58           [-1, 32, 14, 14]              64\n",
            "             ReLU-59           [-1, 32, 14, 14]               0\n",
            "         ResBlock-60           [-1, 32, 14, 14]               0\n",
            "           Conv2d-61             [-1, 64, 7, 7]          18,496\n",
            "      BatchNorm2d-62             [-1, 64, 7, 7]             128\n",
            "             ReLU-63             [-1, 64, 7, 7]               0\n",
            "           Conv2d-64             [-1, 64, 7, 7]          36,928\n",
            "      BatchNorm2d-65             [-1, 64, 7, 7]             128\n",
            "             ReLU-66             [-1, 64, 7, 7]               0\n",
            "  ResNetConvBlock-67             [-1, 64, 7, 7]               0\n",
            "           Conv2d-68             [-1, 64, 7, 7]          36,928\n",
            "      BatchNorm2d-69             [-1, 64, 7, 7]             128\n",
            "             ReLU-70             [-1, 64, 7, 7]               0\n",
            "           Conv2d-71             [-1, 64, 7, 7]          36,928\n",
            "      BatchNorm2d-72             [-1, 64, 7, 7]             128\n",
            "             ReLU-73             [-1, 64, 7, 7]               0\n",
            "         ResBlock-74             [-1, 64, 7, 7]               0\n",
            "           Conv2d-75             [-1, 64, 7, 7]          36,928\n",
            "      BatchNorm2d-76             [-1, 64, 7, 7]             128\n",
            "             ReLU-77             [-1, 64, 7, 7]               0\n",
            "           Conv2d-78             [-1, 64, 7, 7]          36,928\n",
            "      BatchNorm2d-79             [-1, 64, 7, 7]             128\n",
            "             ReLU-80             [-1, 64, 7, 7]               0\n",
            "         ResBlock-81             [-1, 64, 7, 7]               0\n",
            "        AvgPool2d-82             [-1, 64, 1, 1]               0\n",
            "          Flatten-83                   [-1, 64]               0\n",
            "           Linear-84                    [-1, 3]             195\n",
            "          Softmax-85                    [-1, 3]               0\n",
            "================================================================\n",
            "Total params: 271,139\n",
            "Trainable params: 271,139\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.18\n",
            "Forward/backward pass size (MB): 8.69\n",
            "Params size (MB): 1.03\n",
            "Estimated Total Size (MB): 9.90\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "class ResBlock(nn.Module): # блок со сложением входного слоя и конечного\n",
        "    def __init__(self, channels):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(channels, channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels)\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(x + self.conv(x))\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNetConvBlock(nn.Module): # сверточный блок с задаваемым кол-вом входных/выходных каналов\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResNetConvBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 2, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.conv0 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 7, 2, 7),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2, 1)\n",
        "        )\n",
        "        self.layer1 = ResBlock(8)\n",
        "        self.conv1 = ResNetConvBlock(8, 16)\n",
        "        self.layer2 = ResBlock(16)\n",
        "        self.conv2 = ResNetConvBlock(16, 32)\n",
        "        self.layer3 = ResBlock(32)\n",
        "        self.conv3 = ResNetConvBlock(32, 64)\n",
        "        self.layer4 = ResBlock(64)\n",
        "        self.post_processing = nn.Sequential(\n",
        "            nn.AvgPool2d(7),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 3),\n",
        "            nn.Softmax(-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv0(x)\n",
        "\n",
        "        for i in range(2):\n",
        "            out = self.layer1(out)\n",
        "        out = self.conv1(out)\n",
        "\n",
        "        for i in range(2):\n",
        "            out = self.layer2(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        for i in range(2):\n",
        "            out = self.layer3(out)\n",
        "        out = self.conv3(out)\n",
        "\n",
        "        for i in range(2):\n",
        "            out = self.layer4(out)\n",
        "\n",
        "        out = self.post_processing(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "resnet = ResNetModel().to(device)\n",
        "summary(resnet, (1, 216, 216))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dyuzR3jg-wC"
      },
      "source": [
        "# Загрузка датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ss1sjSu7wQcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aeca561-1c33-4060-e541-7c662d5254d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c  ml-intensive-yandex-autumn-2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rxTuMBBuweZh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "a7601cc3-e61b-4a38-b201-151d3e49514d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'ml-intensive-yandex-autumn-2023.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-de9fd94c1541>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ml-intensive-yandex-autumn-2023.zip'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml-intensive-yandex-autumn-2023.zip'"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('ml-intensive-yandex-autumn-2023.zip') as zf:\n",
        "    zf.extractall('.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0KqflElhS3C"
      },
      "source": [
        "# Обучение U-Net'а"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE2lTvZxhZg2"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "from torchvision.transforms.v2.functional import resize\n",
        "import os\n",
        "\n",
        "\n",
        "class MySegmentationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_dir, mask_dir=None,\n",
        "                 transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.mask_dir = mask_dir\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(list(Path(self.img_dir).iterdir()))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, \"img_\" + str(idx) + \".png\")\n",
        "        image = to_tensor(Image.open(img_name)) # загрузка картинки\n",
        "\n",
        "        if self.mask_dir:\n",
        "            mask_name = os.path.join(self.mask_dir, \"img_\" + str(idx) + \".png\")\n",
        "            mask = resize(to_tensor(Image.open(mask_name)), 216, antialias=True) # загрузка маски в случае тренировки\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            if self.mask_dir:\n",
        "                mask = self.mask_transform(mask) # преобразование изображений\n",
        "\n",
        "        if self.mask_dir:\n",
        "            return image, mask\n",
        "        else:\n",
        "            return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-NFeVELko-g"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "\n",
        "s_model = unet\n",
        "s_optimizer = torch.optim.Adam(s_model.parameters(), lr = 0.01)\n",
        "s_criterion = nn.MSELoss()\n",
        "\n",
        "s_dataset = MySegmentationDataset('data/train_images',\n",
        "                                  'data/train_lung_masks')\n",
        "\n",
        "s_train_dataset, s_valid_dataset = random_split(s_dataset, (0.8, 0.2))\n",
        "\n",
        "s_train_loader = DataLoader(s_train_dataset, batch_size=16)\n",
        "s_valid_loader = DataLoader(s_valid_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oockg6mvnn2E"
      },
      "outputs": [],
      "source": [
        "from ignite.engine import create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Loss\n",
        "\n",
        "s_trainer = create_supervised_trainer(s_model, s_optimizer, s_criterion, device)\n",
        "\n",
        "s_metrics = {\n",
        "    'Loss': Loss(s_criterion)\n",
        "}\n",
        "\n",
        "s_train_hist_loss, s_valid_hist_loss = [], []\n",
        "\n",
        "s_train_evaluator = create_supervised_evaluator(s_model, s_metrics, device)\n",
        "s_valid_evaluator = create_supervised_evaluator(s_model, s_metrics, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5EMWP4rocxY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def show_s_loss(engine, train_hist_loss, valid_hist_loss):\n",
        "    clear_output()\n",
        "\n",
        "    ln = len(train_hist_loss)\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "\n",
        "    plt.subplot(1, 1, 1)\n",
        "    plt.title('MSE')\n",
        "    plt.plot(torch.arange(ln), train_hist_loss)\n",
        "    plt.plot(torch.arange(ln), valid_hist_loss)\n",
        "    plt.yscale('log')\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNU3CLsEo534"
      },
      "outputs": [],
      "source": [
        "from ignite.engine import Events\n",
        "\n",
        "# тут можно добавить лог итераций при желании\n",
        "\n",
        "def compute_s_epoch_results(engine):\n",
        "    s_train_evaluator.run(s_train_loader)\n",
        "    s_valid_evaluator.run(s_valid_loader)\n",
        "\n",
        "s_trainer.add_event_handler(Events.EPOCH_COMPLETED, compute_s_epoch_results)\n",
        "\n",
        "def log_s_epoch_results(engine, label):\n",
        "    if label == 'Train':\n",
        "        s_train_hist_loss.append(engine.state.metrics['Loss'])\n",
        "    elif label == 'Valid':\n",
        "        s_valid_hist_loss.append(engine.state.metrics['Loss'])\n",
        "\n",
        "\n",
        "s_train_evaluator.add_event_handler(Events.EPOCH_COMPLETED, log_s_epoch_results, \"Train\")\n",
        "s_valid_evaluator.add_event_handler(Events.EPOCH_COMPLETED, log_s_epoch_results, \"Valid\")\n",
        "s_valid_evaluator.add_event_handler(Events.EPOCH_COMPLETED, show_s_loss,\n",
        "                                    s_train_hist_loss, s_valid_hist_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PojysJCepLu4"
      },
      "outputs": [],
      "source": [
        "from ignite.handlers.param_scheduler import ReduceLROnPlateauScheduler\n",
        "\n",
        "s_scheduler = ReduceLROnPlateauScheduler(\n",
        "    s_optimizer,\n",
        "    metric_name=\"Loss\",\n",
        "    factor=0.5,\n",
        "    patience=1,\n",
        "    threshold=0.05\n",
        ")\n",
        "\n",
        "def print_s_lr():\n",
        "    for param_group in s_optimizer.param_groups:\n",
        "        print(f\"Learning rate = {param_group['lr']}\")\n",
        "\n",
        "s_valid_evaluator.add_event_handler(Events.COMPLETED, s_scheduler)\n",
        "s_valid_evaluator.add_event_handler(Events.COMPLETED, print_s_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-xBfklypQtA"
      },
      "outputs": [],
      "source": [
        "s_trainer.run(s_train_loader, 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unXOys7TKaax"
      },
      "outputs": [],
      "source": [
        "s_test_dataset = MySegmentationDataset('data/test_images')\n",
        "\n",
        "s_model.eval()\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "for idx, i in enumerate(range(15, 20)):\n",
        "    img = resize(s_test_dataset[i], 216, antialias=True).cpu().permute(1, 2, 0).detach().numpy()\n",
        "    with torch.no_grad():\n",
        "        pred = s_model(s_test_dataset[i].unsqueeze(1).to(device))[0].cpu().permute(1, 2, 0).detach().numpy()\n",
        "\n",
        "    plt.subplot(3, 5, idx + 1)\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.subplot(3, 5, idx + 6)\n",
        "    plt.imshow(pred, cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.subplot(3, 5, idx + 11)\n",
        "    plt.imshow(img * pred, cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30jNyr3wuFQS"
      },
      "source": [
        "\n",
        "# Обучение ResNet'а"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irwNsyu1x0Cf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "s_model.eval()\n",
        "\n",
        "class MyClassificationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_dir, model, csv_file=None, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "        if csv_file:\n",
        "            self.csv, self.answers = True, pd.read_csv(csv_file)\n",
        "        else:\n",
        "            self.csv = False\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(list(Path(self.img_dir).iterdir()))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, \"img_\" + str(idx) + \".png\")\n",
        "\n",
        "        img = resize(to_tensor(Image.open(img_name)), 216, antialias=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            mask = self.model(to_tensor(Image.open(img_name)).unsqueeze(1).to(device))[0]\n",
        "        image = img * mask # получение сегментированных легких\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image) # преобразования картинки\n",
        "\n",
        "        if self.csv:\n",
        "            answer = self.answers.iloc[idx, 1] # получение ответа в случае тренировки\n",
        "\n",
        "        if self.csv:\n",
        "            return image, answer\n",
        "        else:\n",
        "            return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cYSZIBwBooZ"
      },
      "outputs": [],
      "source": [
        "c_model = resnet\n",
        "c_optimizer = torch.optim.Adam(c_model.parameters(), lr = 0.02)\n",
        "c_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "c_dataset = MyClassificationDataset('data/train_images',\n",
        "                                    s_model,\n",
        "                                    'data/train_answers.csv')\n",
        "\n",
        "c_train_dataset, c_valid_dataset = random_split(c_dataset, (0.8, 0.2))\n",
        "\n",
        "c_train_loader = DataLoader(c_train_dataset, batch_size=16)\n",
        "c_valid_loader = DataLoader(c_valid_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n1P4zOpDiJZ"
      },
      "outputs": [],
      "source": [
        "from ignite.metrics import Recall, Precision, Fbeta\n",
        "\n",
        "precision = Precision(average=False)\n",
        "recall = Recall(average=False)\n",
        "\n",
        "c_trainer = create_supervised_trainer(c_model, c_optimizer, c_criterion, device)\n",
        "\n",
        "c_metrics = {\n",
        "    'Loss': Loss(c_criterion),\n",
        "    'F1' : Fbeta(1.0, precision=precision, recall=recall)\n",
        "}\n",
        "\n",
        "c_train_hist_loss, c_valid_hist_loss = [], []\n",
        "c_train_hist_metric, c_valid_hist_metric = [], []\n",
        "\n",
        "c_train_evaluator = create_supervised_evaluator(c_model, c_metrics, device)\n",
        "c_valid_evaluator = create_supervised_evaluator(c_model, c_metrics, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehNPIyH3IDa1"
      },
      "outputs": [],
      "source": [
        "def show_c_losses(engine, train_hist_loss, valid_hist_loss,\n",
        "                  train_hist_metric, valid_hist_metric):\n",
        "    clear_output()\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('CE Loss')\n",
        "    plt.plot(torch.arange(len(train_hist_loss)), train_hist_loss)\n",
        "    plt.plot(torch.arange(len(valid_hist_loss)), valid_hist_loss)\n",
        "    plt.yscale('log')\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('F1')\n",
        "    plt.plot(torch.arange(len(train_hist_metric)), train_hist_metric)\n",
        "    plt.plot(torch.arange(len(valid_hist_metric)), valid_hist_metric)\n",
        "    plt.yscale('log')\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX6VJbnYFKOT"
      },
      "outputs": [],
      "source": [
        "# тут можно добавить лог итераций при желании\n",
        "\n",
        "def compute_c_epoch_results(engine):\n",
        "    c_train_evaluator.run(c_train_loader)\n",
        "    c_valid_evaluator.run(c_valid_loader)\n",
        "\n",
        "c_trainer.add_event_handler(Events.EPOCH_COMPLETED, compute_c_epoch_results)\n",
        "\n",
        "def log_c_epoch_results(engine, label):\n",
        "    if label == 'Train':\n",
        "        c_train_hist_loss.append(engine.state.metrics['Loss'])\n",
        "        c_train_hist_metric.append(engine.state.metrics['F1'])\n",
        "    elif label == 'Valid':\n",
        "        c_valid_hist_loss.append(engine.state.metrics['Loss'])\n",
        "        c_valid_hist_metric.append(engine.state.metrics['F1'])\n",
        "\n",
        "\n",
        "c_train_evaluator.add_event_handler(Events.EPOCH_COMPLETED, log_c_epoch_results, \"Train\")\n",
        "c_valid_evaluator.add_event_handler(Events.EPOCH_COMPLETED, log_c_epoch_results, \"Valid\")\n",
        "c_valid_evaluator.add_event_handler(Events.EPOCH_COMPLETED, show_c_losses,\n",
        "                                    c_train_hist_loss, c_valid_hist_loss,\n",
        "                                    c_train_hist_metric, c_valid_hist_metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIojaNsALLyX"
      },
      "outputs": [],
      "source": [
        "c_scheduler = ReduceLROnPlateauScheduler(\n",
        "    c_optimizer,\n",
        "    metric_name=\"Loss\",\n",
        "    factor=0.5,\n",
        "    patience=1,\n",
        "    threshold=0.05\n",
        ")\n",
        "\n",
        "def print_c_lr():\n",
        "    for param_group in c_optimizer.param_groups:\n",
        "        print(f\"Learning rate = {param_group['lr']}\")\n",
        "\n",
        "c_valid_evaluator.add_event_handler(Events.COMPLETED, c_scheduler)\n",
        "c_valid_evaluator.add_event_handler(Events.COMPLETED, print_c_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mx2U6dnMDrS"
      },
      "outputs": [],
      "source": [
        "c_trainer.run(c_train_loader, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cc7CHHTqZRf"
      },
      "outputs": [],
      "source": [
        "c_model.eval()\n",
        "\n",
        "test_dataset = MyClassificationDataset('data/test_images', s_model)\n",
        "\n",
        "df = pd.DataFrame(columns=['id', 'target_feature'])\n",
        "for i in range(len(test_dataset)):\n",
        "    with torch.no_grad():\n",
        "        pred = torch.argmax(c_model(test_dataset[i].unsqueeze(1).to(device))).cpu().detach().numpy()\n",
        "    df = pd.concat([df, pd.DataFrame({'id': [i],'target_feature': pred})],\n",
        "                   ignore_index=True)\n",
        "\n",
        "df.to_csv('./preds.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}